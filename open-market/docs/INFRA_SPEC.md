# ğŸ—ï¸ ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­ (INFRA_SPEC.md)

> **ë‹´ë‹¹**: LLM Agent
> **ë²”ìœ„**: Docker, CI/CD, ëª¨ë‹ˆí„°ë§, í´ë¼ìš°ë“œ ì¸í”„ë¼

---

## ë¡œì»¬ ê°œë°œ í™˜ê²½ (Docker Compose)

### ì•„í‚¤í…ì²˜
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Compose Network                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  MySQL   â”‚  â”‚  Redis   â”‚  â”‚  Kafka   â”‚  â”‚ Elastic  â”‚        â”‚
â”‚  â”‚  :3306   â”‚  â”‚  :6379   â”‚  â”‚  :9092   â”‚  â”‚  :9200   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚Zookeeper â”‚  â”‚  Kibana  â”‚  â”‚ PG-Mock  â”‚  â”‚Ch-Mock   â”‚        â”‚
â”‚  â”‚  :2181   â”‚  â”‚  :5601   â”‚  â”‚  :8081   â”‚  â”‚  :8082   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Host Machine:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend  â”‚  â”‚ Frontend â”‚
â”‚  :8080   â”‚  â”‚  :3000   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### docker-compose.yml
```yaml
version: '3.8'

services:
  # ============================================
  # Database
  # ============================================
  mysql:
    image: mysql:8.0
    container_name: open-market-mysql
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: open_market
      MYSQL_USER: market
      MYSQL_PASSWORD: market123
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init/mysql:/docker-entrypoint-initdb.d
    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================
  # Cache & Session
  # ============================================
  redis:
    image: redis:7.0-alpine
    container_name: open-market-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================
  # Message Queue
  # ============================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: open-market-zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: open-market-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: open-market-kafka-ui
    depends_on:
      - kafka
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  # ============================================
  # Search Engine
  # ============================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: open-market-elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: open-market-kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200

  # ============================================
  # Mock Servers
  # ============================================
  pg-mock:
    build:
      context: ../mock-servers/pg-mock
      dockerfile: Dockerfile
    container_name: open-market-pg-mock
    ports:
      - "8081:8081"
    environment:
      PORT: 8081
      NODE_ENV: development

  channel-mock:
    build:
      context: ../mock-servers/channel-mock
      dockerfile: Dockerfile
    container_name: open-market-channel-mock
    ports:
      - "8082:8082"
    environment:
      PORT: 8082
      NODE_ENV: development

volumes:
  mysql_data:
  redis_data:
  es_data:

networks:
  default:
    name: open-market-network
```

---

## ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸

### MySQL ì´ˆê¸°í™” (init/mysql/01_schema.sql)
```sql
-- ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
SET NAMES utf8mb4;
SET CHARACTER SET utf8mb4;

-- íšŒì› í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS members (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    email VARCHAR(255) NOT NULL UNIQUE,
    password VARCHAR(255) NOT NULL,
    name VARCHAR(100) NOT NULL,
    phone VARCHAR(20),
    role ENUM('BUYER', 'SELLER', 'ADMIN') NOT NULL DEFAULT 'BUYER',
    status ENUM('ACTIVE', 'INACTIVE', 'SUSPENDED') NOT NULL DEFAULT 'ACTIVE',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_email (email),
    INDEX idx_role (role)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ì¹´í…Œê³ ë¦¬ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS categories (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    parent_id BIGINT,
    name VARCHAR(100) NOT NULL,
    depth INT NOT NULL DEFAULT 0,
    sort_order INT NOT NULL DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (parent_id) REFERENCES categories(id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ìƒí’ˆ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS products (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    seller_id BIGINT NOT NULL,
    category_id BIGINT NOT NULL,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    price DECIMAL(15, 2) NOT NULL,
    status ENUM('DRAFT', 'ON_SALE', 'SOLD_OUT', 'HIDDEN', 'DELETED') NOT NULL DEFAULT 'DRAFT',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (seller_id) REFERENCES members(id),
    FOREIGN KEY (category_id) REFERENCES categories(id),
    INDEX idx_seller (seller_id),
    INDEX idx_category (category_id),
    INDEX idx_status (status),
    FULLTEXT INDEX idx_name (name)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ìƒí’ˆ ì˜µì…˜ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS product_options (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id BIGINT NOT NULL,
    name VARCHAR(100) NOT NULL,
    additional_price DECIMAL(15, 2) NOT NULL DEFAULT 0,
    stock INT NOT NULL DEFAULT 0,
    FOREIGN KEY (product_id) REFERENCES products(id),
    INDEX idx_product (product_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ìƒí’ˆ ì´ë¯¸ì§€ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS product_images (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id BIGINT NOT NULL,
    url VARCHAR(500) NOT NULL,
    sort_order INT NOT NULL DEFAULT 0,
    FOREIGN KEY (product_id) REFERENCES products(id),
    INDEX idx_product (product_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ì£¼ë¬¸ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS orders (
    id VARCHAR(36) PRIMARY KEY,
    buyer_id BIGINT NOT NULL,
    total_amount DECIMAL(15, 2) NOT NULL,
    status ENUM('PENDING', 'PAID', 'PREPARING', 'SHIPPED', 'DELIVERED', 'CANCELLED', 'REFUNDED') NOT NULL DEFAULT 'PENDING',
    recipient_name VARCHAR(100) NOT NULL,
    recipient_phone VARCHAR(20) NOT NULL,
    address VARCHAR(500) NOT NULL,
    address_detail VARCHAR(200),
    zip_code VARCHAR(10) NOT NULL,
    ordered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (buyer_id) REFERENCES members(id),
    INDEX idx_buyer (buyer_id),
    INDEX idx_status (status),
    INDEX idx_ordered_at (ordered_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ì£¼ë¬¸ ì•„ì´í…œ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS order_items (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    order_id VARCHAR(36) NOT NULL,
    product_id BIGINT NOT NULL,
    option_id BIGINT NOT NULL,
    quantity INT NOT NULL,
    price DECIMAL(15, 2) NOT NULL,
    item_status ENUM('ORDERED', 'SHIPPED', 'DELIVERED', 'CANCELLED', 'REFUNDED') NOT NULL DEFAULT 'ORDERED',
    FOREIGN KEY (order_id) REFERENCES orders(id),
    FOREIGN KEY (product_id) REFERENCES products(id),
    FOREIGN KEY (option_id) REFERENCES product_options(id),
    INDEX idx_order (order_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ê²°ì œ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS payments (
    id VARCHAR(36) PRIMARY KEY,
    order_id VARCHAR(36) NOT NULL UNIQUE,
    pg_provider ENUM('TOSS_PAYMENTS', 'KAKAO_PAY', 'NAVER_PAY', 'DANAL') NOT NULL,
    pg_payment_key VARCHAR(100),
    amount DECIMAL(15, 2) NOT NULL,
    status ENUM('PENDING', 'PAID', 'CANCELLED', 'FAILED', 'PARTIAL_CANCELLED') NOT NULL DEFAULT 'PENDING',
    paid_at TIMESTAMP NULL,
    cancelled_at TIMESTAMP NULL,
    fail_reason VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (order_id) REFERENCES orders(id),
    INDEX idx_status (status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ì •ì‚° í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS settlements (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    seller_id BIGINT NOT NULL,
    settlement_date DATE NOT NULL,
    sales_amount DECIMAL(15, 2) NOT NULL,
    fee_amount DECIMAL(15, 2) NOT NULL,
    settlement_amount DECIMAL(15, 2) NOT NULL,
    status ENUM('PENDING', 'CONFIRMED', 'PAID') NOT NULL DEFAULT 'PENDING',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (seller_id) REFERENCES members(id),
    INDEX idx_seller (seller_id),
    INDEX idx_date (settlement_date)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
```

### MySQL ì´ˆê¸° ë°ì´í„° (init/mysql/02_seed.sql)
```sql
-- ì¹´í…Œê³ ë¦¬ ì‹œë“œ ë°ì´í„°
INSERT INTO categories (id, parent_id, name, depth, sort_order) VALUES
(1, NULL, 'ì˜ë¥˜', 0, 1),
(2, NULL, 'ì „ìì œí’ˆ', 0, 2),
(3, NULL, 'ì‹í’ˆ', 0, 3),
(4, 1, 'ìƒì˜', 1, 1),
(5, 1, 'í•˜ì˜', 1, 2),
(6, 1, 'ì•„ìš°í„°', 1, 3),
(7, 2, 'ìŠ¤ë§ˆíŠ¸í°', 1, 1),
(8, 2, 'ë…¸íŠ¸ë¶', 1, 2),
(9, 2, 'ê°€ì „', 1, 3);

-- í…ŒìŠ¤íŠ¸ íšŒì›
INSERT INTO members (email, password, name, phone, role) VALUES
('buyer@test.com', '$2a$10$...', 'í…ŒìŠ¤íŠ¸êµ¬ë§¤ì', '010-1234-5678', 'BUYER'),
('seller@test.com', '$2a$10$...', 'í…ŒìŠ¤íŠ¸íŒë§¤ì', '010-8765-4321', 'SELLER'),
('admin@test.com', '$2a$10$...', 'ê´€ë¦¬ì', '010-0000-0000', 'ADMIN');
```

### Elasticsearch ì¸ë±ìŠ¤ ë§¤í•‘ (init/elasticsearch/products_mapping.json)
```json
{
  "mappings": {
    "properties": {
      "id": { "type": "long" },
      "name": {
        "type": "text",
        "analyzer": "korean",
        "fields": {
          "keyword": { "type": "keyword" },
          "autocomplete": {
            "type": "text",
            "analyzer": "autocomplete"
          }
        }
      },
      "description": {
        "type": "text",
        "analyzer": "korean"
      },
      "categoryId": { "type": "long" },
      "categoryName": { "type": "keyword" },
      "sellerId": { "type": "long" },
      "sellerName": { "type": "keyword" },
      "price": { "type": "long" },
      "status": { "type": "keyword" },
      "createdAt": { "type": "date" },
      "salesCount": { "type": "long" },
      "reviewCount": { "type": "long" },
      "reviewAvgScore": { "type": "float" }
    }
  },
  "settings": {
    "analysis": {
      "analyzer": {
        "korean": {
          "type": "custom",
          "tokenizer": "nori_tokenizer"
        },
        "autocomplete": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase", "edge_ngram_filter"]
        }
      },
      "filter": {
        "edge_ngram_filter": {
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 20
        }
      }
    }
  }
}
```

---

## Dockerfile

### Backend Dockerfile
```dockerfile
# infra/docker/backend/Dockerfile
FROM eclipse-temurin:21-jdk-alpine AS builder

WORKDIR /app
COPY gradlew .
COPY gradle gradle
COPY build.gradle.kts .
COPY settings.gradle.kts .
COPY src src

RUN chmod +x ./gradlew
RUN ./gradlew bootJar -x test

FROM eclipse-temurin:21-jre-alpine

WORKDIR /app
COPY --from=builder /app/build/libs/*.jar app.jar

ENV JAVA_OPTS="-Xms512m -Xmx1024m"

EXPOSE 8080
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

### Frontend Dockerfile
```dockerfile
# infra/docker/frontend/Dockerfile
FROM node:20-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

FROM node:20-alpine AS runner

WORKDIR /app
ENV NODE_ENV=production

COPY --from=builder /app/public ./public
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static

EXPOSE 3000
ENV PORT 3000
ENV HOSTNAME "0.0.0.0"

CMD ["node", "server.js"]
```

---

## CI/CD (GitHub Actions)

### Backend CI (.github/workflows/backend-ci.yml)
```yaml
name: Backend CI

on:
  push:
    branches: [main, develop]
    paths:
      - 'backend/**'
  pull_request:
    branches: [main, develop]
    paths:
      - 'backend/**'

jobs:
  build:
    runs-on: ubuntu-latest
    
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: root
          MYSQL_DATABASE: open_market_test
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3
      
      redis:
        image: redis:7.0-alpine
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'gradle'
      
      - name: Grant execute permission
        run: chmod +x ./backend/gradlew
      
      - name: Build and Test
        working-directory: ./backend
        run: ./gradlew build
        env:
          SPRING_PROFILES_ACTIVE: test
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: backend/build/reports/tests/

  docker:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./infra/docker/backend/Dockerfile
          push: true
          tags: |
            ${{ secrets.DOCKER_USERNAME }}/open-market-backend:latest
            ${{ secrets.DOCKER_USERNAME }}/open-market-backend:${{ github.sha }}
```

### Frontend CI (.github/workflows/frontend-ci.yml)
```yaml
name: Frontend CI

on:
  push:
    branches: [main, develop]
    paths:
      - 'frontend/**'
  pull_request:
    branches: [main, develop]
    paths:
      - 'frontend/**'

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci
      
      - name: Lint
        working-directory: ./frontend
        run: npm run lint
      
      - name: Type check
        working-directory: ./frontend
        run: npm run type-check
      
      - name: Build
        working-directory: ./frontend
        run: npm run build
        env:
          NEXT_PUBLIC_API_URL: http://api.example.com

  docker:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./infra/docker/frontend/Dockerfile
          push: true
          tags: |
            ${{ secrets.DOCKER_USERNAME }}/open-market-frontend:latest
```

---

## ëª¨ë‹ˆí„°ë§

### Prometheus ì„¤ì • (monitoring/prometheus/prometheus.yml)
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'backend'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['backend:8080']
  
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka:9092']
  
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
```

### Grafana ëŒ€ì‹œë³´ë“œ
```
ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ:
1. JVM Metrics (í™ ë©”ëª¨ë¦¬, GC, ìŠ¤ë ˆë“œ)
2. HTTP Request Metrics (ìš”ì²­ìˆ˜, ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨)
3. Database Metrics (ì»¤ë„¥ì…˜ í’€, ì¿¼ë¦¬ ì‹œê°„)
4. Kafka Metrics (ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰, ì§€ì—°)
5. Business Metrics (ì£¼ë¬¸ìˆ˜, ê²°ì œ ì„±ê³µë¥ )
```

---

## í´ë” êµ¬ì¡° ìµœì¢…

```
infra/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ docker-compose.prod.yml
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ init/
â”‚       â”œâ”€â”€ mysql/
â”‚       â”‚   â”œâ”€â”€ 01_schema.sql
â”‚       â”‚   â””â”€â”€ 02_seed.sql
â”‚       â””â”€â”€ elasticsearch/
â”‚           â””â”€â”€ products_mapping.json
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ backend-ci.yml
â”‚       â”œâ”€â”€ frontend-ci.yml
â”‚       â””â”€â”€ deploy.yml
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ dashboards/
â”‚           â”œâ”€â”€ jvm.json
â”‚           â””â”€â”€ business.json
â”‚
â””â”€â”€ terraform/               # Optional - AWS
    â”œâ”€â”€ main.tf
    â”œâ”€â”€ variables.tf
    â”œâ”€â”€ outputs.tf
    â””â”€â”€ modules/
        â”œâ”€â”€ vpc/
        â”œâ”€â”€ ecs/
        â””â”€â”€ rds/
```
